{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratchbook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "import PIL.Image as Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciate the model\n",
    "model = models.vgg19()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list\n",
    "features_blobs = list()\n",
    "\n",
    "# Create hook to dump features maps into the list created above\n",
    "def hook_feature(module, input, output): \n",
    "    features_blobs.append(output.data.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (1): ReLU(inplace)\n",
       "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (3): ReLU(inplace)\n",
       "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (6): ReLU(inplace)\n",
       "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (8): ReLU(inplace)\n",
       "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (11): ReLU(inplace)\n",
       "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (13): ReLU(inplace)\n",
       "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (15): ReLU(inplace)\n",
       "  (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (17): ReLU(inplace)\n",
       "  (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (20): ReLU(inplace)\n",
       "  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (22): ReLU(inplace)\n",
       "  (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (24): ReLU(inplace)\n",
       "  (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (26): ReLU(inplace)\n",
       "  (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (29): ReLU(inplace)\n",
       "  (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (31): ReLU(inplace)\n",
       "  (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (33): ReLU(inplace)\n",
       "  (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (35): ReLU(inplace)\n",
       "  (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get model features\n",
    "features = model._modules[\"features\"]\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can hook any layer from above\n",
    "features._modules.get('0').register_forward_hook(hook_feature);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(\"./examples/pebbles.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the image so that it can be fed to the network\n",
    "preprocess = transforms.Compose([\n",
    "   transforms.Resize(256),\n",
    "   transforms.CenterCrop(224),\n",
    "   transforms.ToTensor(),\n",
    "   #normalize\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.7059, 0.7529, 0.7765,  ..., 0.8118, 0.8353, 0.8314],\n",
       "          [0.6863, 0.7647, 0.7961,  ..., 0.7765, 0.7882, 0.7686],\n",
       "          [0.7137, 0.7686, 0.7725,  ..., 0.7882, 0.7765, 0.7529],\n",
       "          ...,\n",
       "          [0.7176, 0.7255, 0.6863,  ..., 0.1373, 0.1451, 0.1529],\n",
       "          [0.5882, 0.6157, 0.6000,  ..., 0.1333, 0.1373, 0.1333],\n",
       "          [0.4627, 0.5137, 0.5255,  ..., 0.1333, 0.1255, 0.1176]],\n",
       "\n",
       "         [[0.7216, 0.7412, 0.7373,  ..., 0.8353, 0.8510, 0.8471],\n",
       "          [0.7020, 0.7529, 0.7569,  ..., 0.7922, 0.7843, 0.7647],\n",
       "          [0.7255, 0.7451, 0.7333,  ..., 0.7882, 0.7569, 0.7294],\n",
       "          ...,\n",
       "          [0.6431, 0.6510, 0.6314,  ..., 0.1529, 0.1686, 0.1765],\n",
       "          [0.5098, 0.5412, 0.5451,  ..., 0.1725, 0.1765, 0.1765],\n",
       "          [0.3765, 0.4392, 0.4706,  ..., 0.1765, 0.1765, 0.1686]],\n",
       "\n",
       "         [[0.7647, 0.7843, 0.7804,  ..., 0.8353, 0.8627, 0.8588],\n",
       "          [0.7373, 0.7961, 0.7922,  ..., 0.7961, 0.8039, 0.7843],\n",
       "          [0.7529, 0.7843, 0.7686,  ..., 0.7961, 0.7725, 0.7451],\n",
       "          ...,\n",
       "          [0.6510, 0.6588, 0.6314,  ..., 0.1569, 0.1686, 0.1765],\n",
       "          [0.5176, 0.5490, 0.5451,  ..., 0.1804, 0.1843, 0.1843],\n",
       "          [0.3882, 0.4471, 0.4706,  ..., 0.2000, 0.2000, 0.1922]]]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_tensor = preprocess(img)\n",
    "# ``unsqueeze_`` means the transformation is made inplace\n",
    "# Here unsqueeze enables us to create a batch of 1 image\n",
    "img_tensor.unsqueeze_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 64, 224, 224)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Capture the features outputs at the layer given above\n",
    "model.forward(img_tensor)\n",
    "array = np.array(features_blobs[0])\n",
    "array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refactoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_from_layer(model, base_img_path, layer_id):\n",
    "    \"\"\"\n",
    "    Get the features maps outputs from any layer\n",
    "    using a forward pass from a base image\n",
    "    in a VGG model\n",
    "    \n",
    "    Parameters\n",
    "    ------------\n",
    "    - model : torchvision.models.vgg.VGG\n",
    "        Model to be investigated\n",
    "        \n",
    "    - base_img_path : string\n",
    "        Path of the image to be used as input\n",
    "        \n",
    "    - layer_id : int\n",
    "        Layer Number.\n",
    "        Validity range: 0 - 36 (included)\n",
    "        See ``model._modules['features']``\n",
    "        for more details\n",
    "        \n",
    "    Returns\n",
    "    ------------\n",
    "    - layer_output : numpy.ndarray\n",
    "        Array of features maps activations\n",
    "    \"\"\"\n",
    "    if not layer_id in np.arange(0, 37):\n",
    "        raise ValueError(\"``layer_id`` argument invalid.  \"\n",
    "                         f\"Got: {layer_id}.  \"\n",
    "                         \"Expected a value between 0 and 36 included.  \")\n",
    "    \n",
    "    \n",
    "    # Create an empty list\n",
    "    features_blobs = list()\n",
    "\n",
    "    # Create hook to dump features maps into the list created above\n",
    "    def hook_feature(module, input, output): \n",
    "        features_blobs.append(output.data.cpu().numpy())\n",
    "        \n",
    "    # Get model features\n",
    "    features = model._modules[\"features\"]\n",
    "    # We can hook any layer from above\n",
    "    features._modules.get(str(layer_id)).register_forward_hook(hook_feature);\n",
    "    \n",
    "    # Load image\n",
    "    img = Image.open(base_img_path)\n",
    "    \n",
    "    # Preprocess the image so that it can be fed to the network\n",
    "    preprocess = transforms.Compose([\n",
    "       transforms.Resize(256),\n",
    "       transforms.CenterCrop(224),\n",
    "       transforms.ToTensor(),\n",
    "       #normalize\n",
    "    ])\n",
    "    img_tensor = preprocess(img)\n",
    "    img_tensor = img_tensor.unsqueeze(0)\n",
    "    \n",
    "    # Capture the features outputs at the layer given above\n",
    "    model.forward(img_tensor)\n",
    "    layer_output = np.array(features_blobs[0])\n",
    "    \n",
    "    return layer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.00540819],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.00177113],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ]],\n",
       "\n",
       "        [[0.03042456, 0.17518562, 0.10294002, ..., 0.12878014,\n",
       "          0.14633478, 0.11153839],\n",
       "         [0.        , 0.17331523, 0.09561723, ..., 0.10231358,\n",
       "          0.13772708, 0.20038472],\n",
       "         [0.        , 0.14968084, 0.07567233, ..., 0.08151257,\n",
       "          0.1288407 , 0.19302253],\n",
       "         ...,\n",
       "         [0.        , 0.13904926, 0.09470867, ..., 0.01174694,\n",
       "          0.01564335, 0.04121323],\n",
       "         [0.        , 0.09933944, 0.04259951, ..., 0.00263656,\n",
       "          0.01827415, 0.02472771],\n",
       "         [0.        , 0.04082219, 0.01349707, ..., 0.00936126,\n",
       "          0.01274523, 0.01967284]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.02301228, ..., 0.06408969,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.03723957, ..., 0.02683328,\n",
       "          0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.01140396, ..., 0.01864308,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.03049532, ..., 0.01081005,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.00456258,\n",
       "          0.        , 0.00197511]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.02632697],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.01430989, 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.05407738, 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ]]]], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_output = get_output_from_layer(model=model, base_img_path=\"./examples/pebbles.jpg\", layer_id=5)\n",
    "layer_output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ima",
   "language": "python",
   "name": "ima"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
